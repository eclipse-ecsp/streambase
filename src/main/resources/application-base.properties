#
# /*
#
#   ******************************************************************************
#
#    Copyright (c) 2023-24 Harman International
#
#
#
#    Licensed under the Apache License, Version 2.0 (the "License");
#
#    you may not use this file except in compliance with the License.
#
#    You may obtain a copy of the License at
#
#
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
#
#    Unless required by applicable law or agreed to in writing, software
#
#    distributed under the License is distributed on an "AS IS" BASIS,
#
#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#
#    See the License for the specific language governing permissions and
#
#    limitations under the License.
#
#
#
#    SPDX-License-Identifier: Apache-2.0
#
#    *******************************************************************************
#
#  */
#

pre.processors=org.eclipse.ecsp.analytics.stream.base.processors.TaskContextInitializer,org.eclipse.ecsp.analytics.stream.base.processors.ProtocolTranslatorPreProcessor,org.eclipse.ecsp.analytics.stream.base.processors.MsgSeqPreProcessor,org.eclipse.ecsp.analytics.stream.base.processors.DeviceMessagingAgentPreProcessor
#the sinker node will always be the last processor in the chain
#Forexample: post.processors=org.eclipse.ecsp.analytics.stream.base.processors.DeviceMessagingAgent,org.eclipse.ecsp.analytics.stream.base.processors.ProtocolTranslatorPostProcessor
#In the above the last processor is ProtocolTranslatorPostProcessor, process will be the sinker for all of the sink topics
post.processors=org.eclipse.ecsp.analytics.stream.base.processors.SchedulerAgentPostProcessor,org.eclipse.ecsp.analytics.stream.base.processors.DeviceMessagingAgentPostProcessor,org.eclipse.ecsp.analytics.stream.base.processors.ProtocolTranslatorPostProcessor
launcher.impl.class.fqn=org.eclipse.ecsp.analytics.stream.base.KafkaStreamsLauncher
#How the processors will be discovered.  (SPIDiscovery, Property based discovery etc)
discovery.impl.class.fqn=org.eclipse.ecsp.analytics.stream.base.discovery.PropBasedDiscoveryServiceImpl
source.topic.name=raw-events
shutdown.hook.wait.ms=60000
log.counts=false
application.id=sample
kafka.ssl.enable=false
kafka.one.way.tls.enable=false
kafka.ssl.endpoint.identification.algorithm=
exec.shutdown.hook=true
#Replication factor for change log
replication.factor=2
mongodb.hosts=localhost
mongodb.port=27017
mongodb.username=admin
mongodb.password=password
mongodb.auth.db=admin
mongodb.name=admin

mongodb.max.wait.time.ms=60000
mongodb.connection.timeout.ms=60000
mongodb.socket.timeout.ms=60000
mongodb.max.connections.per.host=200
mongodb.block.threads.allowed.multiplier=10
mongodb.read.preference=secondaryPreferred
morphia.map.packages=org.eclipse.ecsp,org.eclipse.ecsp.analytics
mongodb.server.selection.timeout=30000
mongodb.taggable.read.preference.enabled=false
mongodb.read.preference.tag=primary_region

device.messaging.event.transformer.class=org.eclipse.ecsp.transform.DeviceMessageIgniteEventTransformer

mqtt.broker.url=tcp://127.0.0.1:1883
mqtt.topic.separator=/
mqtt.config.qos=0
mqtt.user.name = 8146ccc47e84ac1e43de623403133d55
mqtt.user.password = simulator16
mqtt.topic.to.device.infix=/2d
mqtt.service.topic.name=test
mqtt.conn.retry.count=3
mqtt.conn.retry.interval=1000
mqtt.timeout.in.millis=60000
mqtt.max.inflight=1000
mqtt.global.broadcast.retention.topics=
#Should be true, if we want to enable computation of transactional latency in hivemq
wrap.dispatch.event=false
event.wrap.frequency=10

messageid.generator.type=org.eclipse.ecsp.analytics.stream.base.idgen.internal.GlobalMessageIdGenerator
sequence.block.config.maxvalue=10000
event.transformer.classes=genericIgniteEventTransformer
ignite.key.transformer.class=org.eclipse.ecsp.transform.IgniteKeyTransformerStringImpl
dma.event.header.updation.type=messageId
dma.service.retry.interval.divisor=10
dma.service.max.retry=3
dma.service.retry.interval.millis=60000
dma.service.retry.min.threshold.millis=1000
shoulder.tap.retry.interval.divisor=10
shoulder.tap.max.retry=3
shoulder.tap.retry.interval.millis=60000
shoulder.tap.retry.min.threshold.millis=1000
dma.auto.offset.reset=latest
#Shoulder tap invoker implementation class.
#Possible values:
#1) Default, Dummy (no invocation) Impl - org.eclipse.ecsp.stream.dma.shouldertap.DummyShoulderTapInvokerImpl
#2) WAM API implementation - org.eclipse.ecsp.stream.dma.shouldertap.ShoulderTapInvokerWAMImpl
#3) Vehicle Notification service - org.eclipse.ecsp.stream.dma.shouldertap.ShoulderTapInvokerVehicleNotificationImpl
dma.shoulder.tap.invoker.impl.class=org.eclipse.ecsp.stream.dma.shouldertap.DummyShoulderTapInvokerImpl
# Shoulder tap WAM API Send SMS endpoint
dma.shoulder.tap.invoker.wam.send.sms.url=https://com.dummy.test.com/v1.0/m2m/sms/send/
# Shoulder tap WAM API SMS Transaction Status endpoint
dma.shoulder.tap.invoker.wam.sms.transaction.status.url=https://com.dummy.test.com/v1.0/m2m/sim/transaction/
# Shoulder tap WAM API SMS priority. Applicable values: HIGH, LOW. Default is HIGH.
dma.shoulder.tap.wam.sms.priority=HIGH
# Shoulder tap WAM API SMS validity hour. Value in hours: default is 72 hours.
dma.shoulder.tap.wam.sms.validity.hours=72
# Shoulder tap WAM API SMS call: flag to skip the status check of any previous send SMS call before invoking again.
dma.shoulder.tap.wam.send.sms.skip.status.check=true
# Shoulder tap WAM API: max. retry count and interval to invoke send SMS/transaction status until a response.
dma.shoulder.tap.wam.api.max.retry.count=3
dma.shoulder.tap.wam.api.max.retry.interval.ms=30000
dma.shoulder.tap.enabled=false
dma.ttl.expiry.notification.enabled=false
# Default implementation of EventConfigProvider interface
dma.event.config.provider.class=org.eclipse.ecsp.stream.dma.config.DefaultEventConfigProvider

# Default implementation of DMAConfigResolver interface in stream-base.
dma.config.resolver.class=org.eclipse.ecsp.stream.dma.config.DefaultDMAConfigResolver

#Default implementation for DMA post dispatch handler
dma.post.dispatch.handler.class=org.eclipse.ecsp.stream.dma.handler.DefaultPostDispatchHandler
#Default implementation to fetch connection status from API.
dma.connection.status.retriever.impl=org.eclipse.ecsp.analytics.stream.base.utils.DefaultDeviceConnectionStatusRetriever

# Configure whether event needs to be deleted from MongoDB after TTL expiration
dma.remove.on.ttl.expiry.enabled=true

offline.buffer.per.device=false

redis.address=127.0.0.1:6379
redis.sentinels=
redis.master.name=
redis.dns.monitoring.interval=5000
redis.read.mode=MASTER
redis.subscription.mode=MASTER
redis.subscription.conn.min.idle.size=1
redis.subscription.conn.pool.size=50
redis.slave.conn.min.idle.size=32
redis.slave.pool.size=64
redis.master.conn.min.idle.size=32
redis.master.conn.pool.size=128
redis.idle.conn.timeout=600000
redis.conn.timeout=20000
redis.timeout=10000
redis.retry.attempts=3
redis.retry.interval=1500
redis.reconnection.timeout=20000
redis.failed.attempts=3
redis.database=0
redis.password=
redis.subscriptions.per.conn=5
redis.client.name=yellow
redis.conn.min.idle.size=32
redis.conn.pool.size=128
redis.cluster.masters=
redis.scan.interval=10000
redis.netty.threads=32
redis.decode.in.executor=true
redis.executor.threads=32
redis.keep.alive=true
redis.ping.connection.interval=60000
redis.tcp.no.delay=true
redis.transport.mode=NIO
redis.check.slots.coverage=false

#IgniteCache Lua script scan limit
redis.scan.limit=10000
#IgniteCache Lua script for Regex scan
redis.regex.scan.filename=scanregex.txt
#IgniteCache Async operation batch pipeline size
redis.pipeline.size=2

#VehicleId to DeviceId mapping impl class
device.to.vehicle.mapper.impl=org.eclipse.ecsp.analytics.stream.d2v.VehicleToDeviceSingleIdentityMapper
#Vehicle Profile Service URL
http.vp.url=http://internal-andromeda-vehicle-profile-1184319113.us-east-1.elb.amazonaws.com/v1.0/vehicleProfiles/
http.vp.vin.url=http://vehicle-profile-api-int-svc:8080/v1.0/vehicles?clientId=
// Http client properties
http.connection.timeout.in.sec=120
http.read.timeout.in.sec=10
http.write.timeout.in.sec=10
http.keep.alive.duration.in.sec=120
http.max.idle.connections=20
http.vp.auth.header=Authentication
http.vp.service.user=test
http.vp.service.password=pass
// Vehicle profile service URL
http.vp.retry.interval.in.millis=5000
http.vp.max.retry.count=3

#Scheduler Agent Stream Processor
scheduler.agent.topic.name=scheduler
start.device.status.consumer=true
convert.backdoor.kafka.topic.tolowercase=true

#thread status
print.threads.metadata.enabled=true
print.threads.metadata.interval.ms=30000
stream.threads.active.states=CREATED,STARTING,PARTITIONS_REVOKED,PARTITIONS_ASSIGNED,RUNNING,PENDING_SHUTDOWN
stream.threads.dead.states=DEAD
#Message Sequencing
msg.seq.topic.name=test
msg.seq.time.interval.in.millis=0
msg.seq.state.store.changelog.enabled=true

msg.seq.buffer.impl.class=org.eclipse.ecsp.analytics.stream.base.SequenceBufferTreeMapImpl

#Prometheus Configuration
prometheus.agent.port=9100
metrics.prometheus.enabled=true
prometheus.histogram.buckets=0.005, 0.010, 0.015, 0.020, 0.025, 0.030, 0.080, 0.1, 0.2, 0.3
prometheus.data.consumption.metric.buckets=1,5,20,50,100,250,500,1000,1500,3000
prometheus.data.consumption.metric.enabled=false

#rocksdb metrics configuration
rocksdb.metrics.enabled=false
rocksdb.metrics.list=size-all-mem-tables,block-cache-usage,block-cache-pinned-usage,estimate-table-readers-mem,total-sst-files-size,num-running-compactions
rocksdb.metrics.thread.initial.delay.ms=2000
rocksdb.metrics.thread.frequency.ms=180000
metrics.recording.level=DEBUG

backdoor.kafka.max.poll.interval.ms=600000
backdoor.kafka.request.timeout.ms=605000
backdoor.kafka.session.timeout.ms=250000
backdoor.kafka.max.restart.attempts=5
backdoor.kafka.restart.reset.interval.min=30
backdoor.kafka.offset.persistence.delay=60000
backdoor.kafka.enable.auto.commit=false
backdoor.kafka.consumer.default.api.timeout.ms=606000
kafka.streams.offset.persistence.delay=60000
kafka.streams.offset.persistence.init.delay=10000
kafka.streams.offset.persistence.enabled=false
kafka.max.request.size=1000012
kafka.acks.config=1
kafka.buffer.memory.config=33554432
kafka.compression.type.config=none
kafka.retries.config=2147483647
kafka.batch.size.config=16384
kafka.delivery.timeout.ms.config=120000
kafka.linger.ms.config=0
kafka.request.timeout.ms.config=30000
kafka.headers.enabled=false
connections.max.idle.ms=-1
dma.kafka.consumer.poll=50

#RTC 334625 Configuration for maxFailures and maxTimeInterval to be used to recover the thread
kafka.streams.max.failures=10
kafka.streams.max.time.millis=3600000

#LRUCacheMessageGenerator configuration
lru.map.threshold=100000
message.generation.retry.counter=5
message.generation.retry.interval=100

## Flag to enable usage of parameterized constructor for transformers used to accept the properties passed to the application.
## Applicable as the instance creation is via runtime classloader and not spring based.
transformer.inject.property.enable=false

## Reprocessing in DLQ
dlq.max.retry.count=5
dlq.reprocessing.enabled=false

#FilterDMOfflineBufferEntry Impl class
filter.dmoffline.buffer.entry.impl=org.eclipse.ecsp.stream.dma.handler.NoFilterDMOfflineBufferEntryImpl

#Health framework properties
health.mqtt.monitor.enabled=true
health.mqtt.monitor.restart.on.failure=true
health.mongo.monitor.enabled=true
health.mongo.needs.restart.on.failure=true
health.kafka.consumer.group.monitor.enabled=true
health.kafka.consumer.group.needs.restart.on.failure=false
health.device.status.backdoor.monitor.enabled=true
health.device.status.backdoor.monitor.restart.on.failure=false
health.kafka.topics.monitor.enabled=true
health.kafka.topics.monitor.needs.restart.on.failure=true
health.redis.monitor.enabled=false
health.redis.needs.restart.on.failure=true
ignore.bootstrap.failure.monitors=KAFKA_CONSUMER_GROUP_HEALTH_MONITOR,DEVICE_STATUS_BACKDOOR_HEALTH_MONITOR
sp.restart.on.failure=false
sp.restart.wait.time.in.millis=10000
kafka.topics.file.path=/data/topics.txt
expected.min.isr=1
health.service.failure.retry.thrshold=20
health.service.failure.retry.interval.millis=500
health.service.retry.interval.millis=100
health.service.executor.shutdown.millis=2000
health.service.executor.initial.delay=120000
#Diagnostic framework properties
mongo.diagnostic.reporter.enabled=false
property.diagnostic.reporter.enabled=true
#CacheBypass's properties
cache.bypass.queue.initial.capacity=10000
cache.bypass.threads.shutdown.wait.time=2000
dma.num.cache.bypass.threads=1

###############################################################################
#SSL Configuration
key.cert.passwd=*****
trust.cert.passwd=*****

#enabling streaming of event size to kafka for analytics dashboard RTC-301848
kafka.data.consumption.metrics=false
data.consumption.metrics.kafka.topic=data-usage

#Enabling DMA/SCHEDULER Module Configurations For StreamBase
dma.enabled=true
scheduler.enabled=true

#retryRecordIdPatter for custom codec class in DMF
retry.record.id.pattern=recordIds\\\"\\:\\[

#Whether to publish internal cache metrics to prometheus or not.
internal.metrics.enabled=false

#Name of the class which is implementing IgnitePlatform interface to provide platformID
ignite.platform.service.impl.class.name=
mqtt.topic.name.generator.impl.class.name=org.eclipse.ecsp.analytics.stream.base.utils.DefaultMqttTopicNameGeneratorImpl

max.decompress.input.stream.size.in.bytes=1000000000
